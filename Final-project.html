<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Julie Wittrock" />

<meta name="date" content="2025-07-23" />

<title>Practical Machine Learning Course - Final Project</title>

<script src="\\endeavor\analysis$\Clinical Analytics\Tool and Reference\R\library_4.3.1\rmarkdown\rmd\h\pandoc\header-attrs.js"></script>
<script src="\\endeavor\analysis$\Clinical Analytics\Tool and Reference\R\library_4.3.1\jquerylib\lib\3.6.0\jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="\\endeavor\analysis$\Clinical Analytics\Tool and Reference\R\library_4.3.1\rmarkdown\rmd\h\bootstrap\css\bootstrap.min.css" rel="stylesheet" />
<script src="\\endeavor\analysis$\Clinical Analytics\Tool and Reference\R\library_4.3.1\rmarkdown\rmd\h\bootstrap\js\bootstrap.min.js"></script>
<script src="\\endeavor\analysis$\Clinical Analytics\Tool and Reference\R\library_4.3.1\rmarkdown\rmd\h\bootstrap\shim\html5shiv.min.js"></script>
<script src="\\endeavor\analysis$\Clinical Analytics\Tool and Reference\R\library_4.3.1\rmarkdown\rmd\h\bootstrap\shim\respond.min.js"></script>
<style>h1 {font-size: 34px;}
h1.title {font-size: 38px;}
h2 {font-size: 30px;}
h3 {font-size: 24px;}
h4 {font-size: 18px;}
h5 {font-size: 16px;}
h6 {font-size: 12px;}
code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
pre:not([class]) { background-color: white }</style>
<script src="\\endeavor\analysis$\Clinical Analytics\Tool and Reference\R\library_4.3.1\rmarkdown\rmd\h\navigation-1.1\tabsets.js"></script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>







<style type="text/css">
.main-container {
max-width: 940px;
margin-left: auto;
margin-right: auto;
}
img {
max-width:100%;
}
.tabbed-pane {
padding-top: 12px;
}
.html-widget {
margin-bottom: 20px;
}
button.code-folding-btn:focus {
outline: none;
}
summary {
display: list-item;
}
details > summary > p:only-child {
display: inline;
}
pre code {
padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
display: inline-table;
max-height: 500px;
min-height: 44px;
overflow-y: auto;
border: 1px solid #ddd;
border-radius: 4px;
}
.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
content: "\e259";
font-family: 'Glyphicons Halflings';
display: inline-block;
padding: 10px;
border-right: 1px solid #ddd;
}
.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
content: "\e258";
font-family: 'Glyphicons Halflings';
border: none;
}
.tabset-dropdown > .nav-tabs > li.active {
display: block;
}
.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
border: none;
display: inline-block;
border-radius: 4px;
background-color: transparent;
}
.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
display: block;
float: none;
}
.tabset-dropdown > .nav-tabs > li {
display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Practical Machine Learning Course - Final
Project</h1>
<h4 class="author">Julie Wittrock</h4>
<h4 class="date">2025-07-23</h4>

</div>


<div id="background" class="section level2">
<h2>Background</h2>
<p>This is my final project submission for the Practical Machine
Learning course by John Hopkins on Coursera.</p>
<p>The objective of the project was to develop a predictive model using
accelerometer data to accurately classify the quality barbell lifts
performed by athletes.</p>
</div>
<div id="load-libraries" class="section level2">
<h2>Load libraries</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="fu">library</span>(rattle)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span></code></pre></div>
</div>
<div id="load-data-sets" class="section level2">
<h2>Load data sets</h2>
<p>The provided weight lifting exercise data data included data from
accelerometers placed on the belt, forearm, arm, and dumbell of 6
participants. The atheletes were asked to perform barbell lifts
correctly, and then incorrectly in 5 different ways.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>training_raw <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>validation   <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;</span>)</span></code></pre></div>
</div>
<div id="clean-the-training-data" class="section level2">
<h2>Clean the training data</h2>
<p>The first step is to clean the loaded training data. I took the
following steps to get the data into a state where it could be
analyzed:</p>
<ul>
<li>Converted blank string/character variables to NAs so they would be
dealt with properly</li>
<li>Converted the outcome variable to a factor</li>
<li>Removed variables that had more than 95% missing values
<ul>
<li>Ideally, all variables with 80% missing values would be removed, but
in this data set all variables with missing data had more than 97% of
missing values, so 95% was an appropriate threshold</li>
</ul></li>
<li>Removed all non-sensor data that would not be helpful in predicting
the outcome</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>train_clean <span class="ot">&lt;-</span> training_raw <span class="sc">%&gt;%</span> </span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    <span class="co">#convert strings/character where there are blank cells with NA</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.character), <span class="sc">~</span><span class="fu">na_if</span>(<span class="fu">trimws</span>(.), <span class="st">&quot;&quot;</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>    <span class="co">#convert outcome variable into a factor</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">classe =</span> <span class="fu">as.factor</span>(classe)) </span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co">#remove variables with &gt; 95% missing values</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>missing_pct <span class="ot">&lt;-</span> <span class="cf">function</span>(data) {</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>  <span class="fu">sapply</span>(data, <span class="cf">function</span>(x) <span class="fu">mean</span>(<span class="fu">is.na</span>(x))<span class="sc">*</span><span class="dv">100</span>)</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>}</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>vars_over_50_missing <span class="ot">&lt;-</span> <span class="cf">function</span>(data) {</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>  missing_pct <span class="ot">&lt;-</span> <span class="fu">sapply</span>(data, <span class="cf">function</span>(x) <span class="fu">mean</span>(<span class="fu">is.na</span>(x))<span class="sc">*</span><span class="dv">100</span>)</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>  <span class="fu">names</span>(missing_pct[missing_pct <span class="sc">&gt;=</span> <span class="dv">50</span>])</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>}</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="do">##Code to see the list of variables with missing data</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">#missing_pct(train_clean)</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co">#vars_over_50_missing(train_clean)</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>  <span class="co">#all of the variables that have missing data have 97% missing data. </span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>    <span class="co">#Safe in this case to remove more than 95% missing data, although 80% is ideal</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>train_clean <span class="ot">&lt;-</span> train_clean <span class="sc">%&gt;%</span> </span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">where</span>(<span class="sc">~</span> <span class="fu">mean</span>(<span class="sc">!</span><span class="fu">is.na</span>(.)) <span class="sc">&gt;</span> <span class="fl">0.95</span>)) </span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a><span class="co">#drop non-sensor data as it will not be helpful for predicting</span></span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>train_clean <span class="ot">&lt;-</span> train_clean <span class="sc">%&gt;%</span> </span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window))</span></code></pre></div>
</div>
<div id="create-training-and-testing-data-sets" class="section level2">
<h2>Create training and testing data sets</h2>
<p>Using a seed for reproducibility, I randomly split the training data
into a training data set (to develop the model) and testing data set (to
calculate the out of sample error). I have called the project “testing”
set the validation set, for clarity.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">#create test and training data sets from the provided training data ####</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">652</span>)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>inTrain <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> train_clean<span class="sc">$</span>classe, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>train <span class="ot">&lt;-</span> train_clean[inTrain,]</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>test  <span class="ot">&lt;-</span> train_clean[<span class="sc">-</span>inTrain,]</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="fu">dim</span>(train)</span></code></pre></div>
<pre><code>## [1] 13737    53</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">dim</span>(test)</span></code></pre></div>
<pre><code>## [1] 5885   53</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">dim</span>(validation)</span></code></pre></div>
<pre><code>## [1]  20 160</code></pre>
<p>The training set for model building comprised 70% of the entire raw
training set.</p>
</div>
<div id="look-for-highly-correlated-variables" class="section level2">
<h2>Look for highly correlated variables</h2>
<p>Since all of the predictive data originated from accelerometers
placed on the same 6 bodies, capturing multiple measurements of the same
movements, I was concerned about potential multicollinearity. To address
this, I examined the correlations among the variables.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co">#find highly correlated pairs</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>numeric_vars <span class="ot">&lt;-</span> train[, <span class="fu">sapply</span>(train, is.numeric)]</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(numeric_vars, <span class="at">use =</span> <span class="st">&quot;pairwise.complete.obs&quot;</span>)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>high_corr <span class="ot">&lt;-</span> <span class="fu">findCorrelation</span>(cor_matrix, <span class="at">cutoff =</span> <span class="fl">0.9</span>, <span class="at">names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>high_corr</span></code></pre></div>
<pre><code>## [1] &quot;accel_belt_z&quot; &quot;roll_belt&quot;    &quot;accel_belt_y&quot; &quot;accel_belt_x&quot; &quot;gyros_arm_x&quot;</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>    <span class="co">#high degree of multicollinearity, so better to use a tree-based model that handles correlation better</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="co">#corrplot(cor_matrix, method = &quot;color&quot;, type = &quot;upper&quot;, tl.cex = 0.7)</span></span></code></pre></div>
<p>As expected, several variables exhibited high correlation. This
multicollinearity requires careful consideration - either by removing
highly correlated variables or by selecting a modelling approach that
can effectively handle such data structures.</p>
</div>
<div id="create-model" class="section level2">
<h2>Create model</h2>
<p>Random forest models are well suited for classification tasks and are
generally robust to multicollinearity, making them a strong choice for
this dataset.</p>
<p>I implemented a random forest model using 5-fold cross-validation
with the random forest being comprised of 500 trees. This level of
k-fold cross validation should help to ensure that the model is robust
and not over-fitted to the training data.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co">#model using random forest for accuracy and interpretability </span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">892</span>)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">5</span>)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>model_rf <span class="ot">&lt;-</span> <span class="fu">train</span>(classe <span class="sc">~</span> ., <span class="at">data =</span> train, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">trControl =</span> control)<span class="co">#, ntree = 100</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>model_rf<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 27
## 
##         OOB estimate of  error rate: 0.68%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3899    5    2    0    0 0.001792115
## B   21 2630    7    0    0 0.010534236
## C    0   10 2376   10    0 0.008347245
## D    0    2   22 2226    2 0.011545293
## E    0    0    4    8 2513 0.004752475</code></pre>
<p>The model tried 27 variables at each split and had an out-of-bag
estimated error rate of 0.68% - meaning an estimated 99.32% accuracy
based on the training data.</p>
</div>
<div id="model-results-and-out-of-sample-error" class="section level2">
<h2>Model results and out-of-sample error</h2>
<p>The next step is to use the results of the random forest model to
predict the outcome on the testing data to determine it’s performance,
including the out-of-sample error rate.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co">#predictions ####</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_rf, test) </span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>conf_mat <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(predictions, test<span class="sc">$</span>classe)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="co">#out of sample error</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>oos_error <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> conf_mat<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="co">#print(oos_error)</span></span></code></pre></div>
<p>Below is a summary of the performance of the random forest model for
both in and out of sample errors:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co">#Calculate in-sample error</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>train_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_rf, train) </span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>train_conf_mat <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(train_predictions, train<span class="sc">$</span>classe) </span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>in_sample_error <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> train_conf_mat<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co">#Create a comparison table</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>error_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="at">Dataset =</span> <span class="fu">c</span>(<span class="st">&quot;Training (In-Sample)&quot;</span>, <span class="st">&quot;Testing (Out-of-Sample)&quot;</span>),</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="at">Accuracy =</span> <span class="fu">c</span>(train_conf_mat<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>], conf_mat<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]), <span class="at">Error =</span> <span class="fu">c</span>(in_sample_error, oos_error)</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>)</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="co">#Display as a nice table</span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(error_df, <span class="at">caption =</span> <span class="st">&quot;Comparison of In-Sample and Out-of-Sample Errors&quot;</span>, <span class="at">digits =</span> <span class="dv">4</span>)</span></code></pre></div>
<table>
<caption>Comparison of In-Sample and Out-of-Sample Errors</caption>
<thead>
<tr class="header">
<th align="left">Dataset</th>
<th align="right">Accuracy</th>
<th align="right">Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Training (In-Sample)</td>
<td align="right">1.0000</td>
<td align="right">0.0000</td>
</tr>
<tr class="even">
<td align="left">Testing (Out-of-Sample)</td>
<td align="right">0.9929</td>
<td align="right">0.0071</td>
</tr>
</tbody>
</table>
<p>The model had an out-of-sample error rate of 0.71%, meaning that the
model was 99.29% accurate. This is represents excellent predictive
performance of the model.</p>
</div>
<div id="predictions-on-the-testing-set" class="section level2">
<h2>Predictions on the testing set</h2>
<p>First, the same cleaning steps were applied to the testing
(validation) data set as were applied in the initial cleaning of the raw
training data.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>validation_clean <span class="ot">&lt;-</span> validation <span class="sc">%&gt;%</span> </span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.character), <span class="sc">~</span><span class="fu">na_if</span>(<span class="fu">trimws</span>(.), <span class="st">&quot;&quot;</span>))) <span class="co">#convert strings/character where there are blank cells with NA</span></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>  <span class="co">#all of the variables that have missing data have 97% missing data. </span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>    <span class="co">#Safe in this case to remove more than 95% missing data, although 80% is ideal</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>validation_clean <span class="ot">&lt;-</span> validation_clean <span class="sc">%&gt;%</span> </span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">where</span>(<span class="sc">~</span> <span class="fu">mean</span>(<span class="sc">!</span><span class="fu">is.na</span>(.)) <span class="sc">&gt;</span> <span class="fl">0.95</span>)) </span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a><span class="co">#drop non-sensor data as it will not be helpful for predicting</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>validation_clean <span class="ot">&lt;-</span> validation_clean <span class="sc">%&gt;%</span> </span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window))</span></code></pre></div>
<p>Next, use the model make predictions on the cleaned data.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>validation_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_rf, <span class="at">newdata =</span> validation_clean)</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>validation_pred</span></code></pre></div>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->



</body>
</html>
